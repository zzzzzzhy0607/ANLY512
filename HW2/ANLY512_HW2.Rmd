---
title: "ANLY512_HW2"
author: "Hongyang Zheng"
date: "2019/2/10"
output:
  pdf_document: default
  html_document: default
---

# Problem ch.4 #6
#### a)
$$p=\frac{e^{\beta_0+\beta_1*X_1+\beta_2*X_2}}{1+e^{\beta_0+\beta_1*X_1+\beta_2*X_2}}$$
$$=\frac{e^{-6+0.05*40+1*3.5}}{1+e^{-6+0.05*40+1*3.5}}$$
$$=0.3775407$$
The probability this student gets an A is 0.3775407.

#### b)
$$0.5=\frac{e^{-6+0.05*x+3.5}}{1+e^{-6+0.05*x+3.5}}$$
By solving the function, we get $e^{-6+0.05*x+3.5}=1$ and therefore, $x=50$

To get a 50% probability that this student gets an A, this student should study 50 hours.


# Problem ch.4 #10abcd
#### a)
```{r}
library(ISLR)
# Numerical summary
summary(Weekly)
cor(Weekly[, -9])
# Graphical summary
pairs(Weekly)
```

It seems that 'Volume' and 'Year' have a relationship.

#### b)
```{r}
glm.1=glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume, data=Weekly, family = binomial)
summary(glm.1)
```
'Lag2' is statistically significant since its coefficient has a small p-value.

#### c)
```{r}
# Predict the value
glm.1.prob=predict(glm.1, type='response')
n1=length(glm.1.prob)
glm.1.pred=rep('Down', n1)
glm.1.pred[glm.1.prob>0.5]='Up'

# Confusion matrix
table(glm.1.pred, Weekly$Direction)

# Overall fraction of correct predictions
mean(glm.1.pred==Weekly$Direction)
```
The overall fraction of correct predictions is about 56.1%. The confusion matrix also tells us the false positive rate and false negative rate rate.

#### d)
```{r}
# Separate the data into train and test
train.data=Weekly[Weekly$Year<2009,]
test.data=Weekly[Weekly$Year>=2009,]

# Build new model 
glm.2=glm(Direction~Lag2, data=train.data, family='binomial')

# Predict value from the new model
glm.2.prob=predict(glm.2, test.data, type='response')
n2=length(glm.2.prob)
glm.2.pred=rep('Down', n2)
glm.2.pred[glm.2.prob>0.5]='Up'

# Confusion matrix
table(glm.2.pred, test.data$Direction)

# Overall fraction of correct predictions
mean(glm.2.pred==test.data$Direction)
```
The overall fraction of correct predictions is about 62.5%


# Problem Xtra #23
#### a)
```{r}
# Generate Purchase01
np=length(OJ$Purchase)
OJ$Purchase01=rep(0,np)
OJ$Purchase01[OJ$Purchase=='MM']=1
OJ01=OJ[,-1]

# Fit a model
fit.22a=glm(Purchase01~., data=OJ01, family = 'binomial')
summary(fit.22a)
```
After looking at the explanation of these variables, I found that SalePriceMM, SalePriceCH, PriceDiff are related to other variables which have coefficient: SalePriceCH=PriceCH-DiscCH, SalePriceMM=PriceMM-DiscMM, and PriceDiff=PriceCH-DiscCH-PriceMM-DiscMM. Therefore, the coefficient for these three variables are NAs.

For ListPriceDiff, which is equal to PriceCH-PriceMM, since the two prices have been included in the model, the coefficient for ListPriceDiff is NA.

For STORE, maybe StoreID contains the same information, so it is NA.

#### b)
```{r}
# Fit a new model
fit.22b=glm(Purchase01~.-PriceDiff-SalePriceCH-SalePriceMM-ListPriceDiff-STORE, data=OJ01, family = 'binomial')
summary(fit.22b)
```
After removing those variables, there is no change for the model.

#### c)
From b) we know that PriceCH, PriceMM, DiscMM, LoyalCH and PctDiscMM is statistically significant.
```{r}
# Fit a new model
fit.22c=glm(Purchase01~PriceCH+PriceMM+DiscMM+LoyalCH+PctDiscMM, data=OJ01, family = 'binomial')
summary(fit.22c)

# ROC curve
library("pROC")
pred.22c=predict(fit.22c, OJ01)
plot(roc(OJ$Purchase01, pred.22c))
area=auc(roc(OJ$Purchase01, pred.22c))
print(area)
```
The area under the curve is 0.8941, which is approximately 0.89.

#### d)
The odd is:
$$odd=e^{5.5773+2.7315*PriceCH-3.8818*PriceMM+25.1929*DiscMM-6.3725*LoyalCH-47.9810*PctDiscMM}$$
If the price of Minute Maid is decreased by $0.01$, then the odds times $e^0.038818=4\%$.

If the price of Citrus Hill is increased by $0.01$, then the odds times $e^0.027315=2.7\%$.

If the discount offered for Minute Maid is increased by $0.01$, then the odds times $e^0.251929=28.7\%$.


# Problem Xtra #25
```{r}
# Load data
load("~/Desktop/other/Data/mnist_all.RData") 

# Extract data for digit3 and digit5
y.nist = train$y
index <- (y.nist == 3 | y.nist == 5)
x.nist <- train$x[index,]
x.train <- as.data.frame(x.nist)

y.nist1 = test$y
index1 <- (y.nist1 == 3 | y.nist1 == 5)
x.nist1 <- test$x[index1,]
x.test <- as.data.frame(x.nist1)

# y=1 if it is digit5, y=0 if it is digit3
x.train$y <- 0
x.train$y[y.nist[index] == 5] <- 1
x.test$y <- 0
x.test$y[y.nist1[index1] == 5] <- 1
```

```{r}
# Find a variable with large variance
# Calculate all variance for V1 to V784
variance=rep(0,784)
for (i in 1:784)
{
  variance[i]=var(x.train[,i])
}
variance=as.data.frame(variance)
variance$index=seq(1:784)

# Sort from biggest to smallest
variance_sort=variance[order(variance[,1], decreasing=TRUE),]
```

```{r}
# Use V429 with variance = 5919.911
fit.v429=glm(y~V429, data=x.train, family = 'binomial')
summary(fit.v429)
```
The model is: 
$$P(\text{the digit is 5})=\frac{e^{-0.2925354+0.0047854*V429}}{1+e^{-0.2925354+0.0047854*V429}}$$

Determine the fraction of true positives on the test set if the fraction of false positives on the training set is kept to 0.1
```{r}
set.seed(143)
# Confusion matrix
# When threshold=0.5, the FP is close to 0.1.
pred.v429.train=predict(fit.v429, x.train, type='response')
pred.train.429 <- pred.v429.train > 0.5
result=table(x.train$y, pred.train.429)
FP=result[1,2]/(result[1,2]+result[1,1])
print(FP)

# To find more close FP rate, use this for loop
for (x in seq(0.5,0.6,by=0.001))
{
  pred.train.429 <- pred.v429.train > x
  result=table(x.train$y, pred.train.429)
  FP=result[1,2]/(result[1,2]+result[1,1])
  if (round(FP,3)==0.100)
  {
    print(FP)
    print(x)
  }
}

# When x=0.544, the training set has a FP rate about 0.1
# Use this threshold for test data
pred.v429.test=predict(fit.v429, x.test, type='response')
pred.test.429 <- pred.v429.test > 0.544
table(x.test$y, pred.test.429)

# True positive rate
156/(156+736)
```


# Problem Xtra #26
```{r}
# Print the top 10 largest variance index
print(variance_sort[1:10,2])

# After random trying, found V216, V325 have a small correlation
cor(x.train$V325,x.train$V216)

# Fit a model
fit.v325=glm(y~V325+V216, data=x.train, family='binomial')
summary(fit.v325)

# ROC curve 
pred.v325.train=predict(fit.v325, x.train, type='response')
pred.v325.test=predict(fit.v325, x.test, type='response')
plot(roc(x.train$y, pred.v325.train), col=4, xlab='False positive rate', ylab='True positive rate', main='ROC curve')
lines(roc(x.test$y, pred.v325.test), col = 2)
grid(col=2)

# Find the auc rea
auc.train=auc(roc(x.train$y, pred.v325.train), col=4)
auc.test=auc(roc(x.test$y, pred.v325.test), col=2)
print(c(auc.train, auc.test))

# Scatterplot
plot(x.train$V325 ~ x.train$V216, data = x.train, col = x.train$y+2, lwd = 2, asp = 1)
```

From the scatter plot we can see that the boundary between red and green is not so clear, but there is a tendency that red points are located at the top while green points are located at the bottom. Therefore, with test auc=0.8124459, I think this classifier performs good.


# Problem Xtra #27
```{r}
# The top 10 largest variance index
print(variance_sort[1:10,2])

# Fit a model
fit.10=glm(y~V353+V325+V180+V187+V216+V324+V403+V382+V243+V208, data=x.train, family='binomial')
summary(fit.10)

# Use the model to predict train and test data
pred.10.train=predict(fit.10, x.train, type='response')
pred.10.test=predict(fit.10, x.test, type='response')

# ROC curve
plot(roc(x.train$y, pred.10.train), col=4, xlab='False positive rate', ylab='True positive rate', main='ROC curve')
lines(roc(x.test$y, pred.10.test), col = 2)
grid(col=2)

# auc area
auc.train.10=auc(roc(x.train$y, pred.10.train), col=4)
auc.test.10=auc(roc(x.test$y, pred.10.test), col=2)
print(c(auc.train.10, auc.test.10))
```

This classifier performs good since the auc area is bigger than the former two classifier. In addition, the auc on test dataset and train dataset is close, which means the classifier can make a good prediction. 

I think this is not a good way to select 10 predictors, since there are 10 different predictors, we need to collect lots of information to build this model and cannot capture non-linear features. Instead, we can make some transformation of some variables like $x^2$, $logx$ and etc. as predictors to generate 10 predictors.

